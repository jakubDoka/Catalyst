info: generated ir:
native-x86_64-unknown-linux-gnu2\main function u0:0() -> i64 uext fast {
    ss0 = explicit_slot 24
    ss1 = explicit_slot 24
    ss2 = explicit_slot 24
    ss3 = explicit_slot 24
    sig0 = (i64 sret) fast
    sig1 = (i64, i64 uext) fast
    sig2 = (i64 sret) fast
    sig3 = (i64, i64 sarg(24)) fast
    sig4 = (i64, i64 uext) -> i64 fast
    sig5 = (i64, i64 uext) -> i64 fast
    sig6 = (i64, i64 uext) -> i64 fast
    sig7 = (i64) fast
    fn0 = colocated u0:20 sig0
    fn1 = colocated u0:21 sig1
    fn2 = colocated u0:22 sig2
    fn3 = colocated u0:23 sig3
    fn4 = colocated u0:24 sig4
    fn5 = colocated u0:25 sig5
    fn6 = colocated u0:26 sig6
    fn7 = colocated u0:19 sig7

block0:
    v0 = stack_addr.i64 ss0
    call fn0(v0)
    v1 = stack_addr.i64 ss1
    v2 = stack_addr.i64 ss0
    v3 = load.i64 aligned v2
    v4 = load.i64 aligned v2+8
    v5 = load.i64 aligned v2+16
    store aligned v3, v1
    store aligned v4, v1+8
    store aligned v5, v1+16
    v6 = stack_addr.i64 ss1
    v7 = iconst.i64 0
    call fn1(v6, v7)  ; v7 = 0
    v8 = stack_addr.i64 ss1
    v9 = iconst.i64 1
    call fn1(v8, v9)  ; v9 = 1
    v10 = stack_addr.i64 ss1
    v11 = iconst.i64 2
    call fn1(v10, v11)  ; v11 = 2
    v12 = stack_addr.i64 ss2
    call fn2(v12)
    v13 = stack_addr.i64 ss3
    v14 = stack_addr.i64 ss2
    v15 = load.i64 aligned v14
    v16 = load.i64 aligned v14+8
    v17 = load.i64 aligned v14+16
    store aligned v15, v13
    store aligned v16, v13+8
    store aligned v17, v13+16
    v18 = stack_addr.i64 ss3
    v19 = stack_addr.i64 ss1
    call fn3(v18, v19)
    v20 = stack_addr.i64 ss3
    v21 = iconst.i64 0
    v22 = call fn4(v20, v21)  ; v21 = 0
    v23 = iconst.i64 0
    call fn1(v22, v23)  ; v23 = 0
    v24 = stack_addr.i64 ss3
    v25 = iconst.i64 0
    v26 = call fn5(v24, v25)  ; v25 = 0
    v27 = iconst.i64 3
    v28 = call fn6(v26, v27)  ; v27 = 3
    v29 = stack_addr.i64 ss3
    call fn7(v29)
    v30 = load.i64 v28
    return v30
}
native-x86_64-unknown-linux-gnu0\0\Vec\get_ptr[uint] function u0:0(i64, i64 uext) -> i64 fast {
block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 8
    v4 = imul v1, v3  ; v3 = 8
    v5 = iadd v2, v4
    return v5
}
native-x86_64-unknown-linux-gnu0\0\Vec\get_ptr[0\Vec[uint]] function u0:0(i64, i64 uext) -> i64 fast {
block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 24
    v4 = imul v1, v3  ; v3 = 24
    v5 = iadd v2, v4
    return v5
}
native-x86_64-unknown-linux-gnu0\0\Vec\get_mut_ptr[0\Vec[uint]] function u0:0(i64, i64 uext) -> i64 fast {
block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 24
    v4 = imul v1, v3  ; v3 = 24
    v5 = iadd v2, v4
    return v5
}
native-x86_64-unknown-linux-gnu0\0\Vec\push[0\Vec[uint]] function u0:0(i64, i64 sarg(24)) fast {
    sig0 = (i64) fast
    sig1 = (i64, i64 uext) -> i64 fast
    sig2 = (i64, i64 sarg(24)) fast
    fn0 = colocated u0:37 sig0
    fn1 = colocated u0:24 sig1
    fn2 = colocated u0:38 sig2

block0(v0: i64, v1: i64):
    v2 = load.i64 v0+8
    v3 = load.i64 v0+16
    v4 = icmp eq v2, v3
    brnz v4, block1
    jump block2

block2:
    jump block3

block1:
    call fn0(v0)
    jump block3

block3:
    v5 = load.i64 v0+8
    v6 = call fn1(v0, v5)
    call fn2(v6, v1)
    v7 = iconst.i64 1
    v8 = load.i64 v0+8
    v9 = iadd v8, v7  ; v7 = 1
    store v9, v0+8
    return
}
native-x86_64-unknown-linux-gnu3\write[0\Vec[uint]] function u0:0(i64, i64 sarg(24)) fast {
block0(v0: i64, v1: i64):
    v2 = load.i64 aligned v1
    v3 = load.i64 aligned v1+8
    v4 = load.i64 aligned v1+16
    store aligned v2, v0
    store aligned v3, v0+8
    store aligned v4, v0+16
    return
}
native-x86_64-unknown-linux-gnu0\0\Vec\grow[0\Vec[uint]] function u0:0(i64) fast {
    sig0 = (i64, i64 uext) -> i64 fast
    fn0 = u0:40 sig0

block0(v0: i64):
    v1 = iconst.i64 0
    v2 = load.i64 v0+16
    v3 = icmp eq v2, v1  ; v1 = 0
    brnz v3, block1
    jump block2

block2:
    v4 = iconst.i64 2
    v5 = load.i64 v0+16
    v6 = imul v5, v4  ; v4 = 2
    jump block3(v6)

block1:
    v7 = iconst.i64 8
    jump block3(v7)  ; v7 = 8

block3(v8: i64):
    store v8, v0+16
    v9 = load.i64 v0
    v10 = iconst.i64 24
    v11 = load.i64 v0+16
    v12 = imul v11, v10  ; v10 = 24
    v13 = call fn0(v9, v12)
    store v13, v0
    return
}
native-x86_64-unknown-linux-gnu0\0\Vec\new[0\Vec[uint]] function u0:0(i64 sret) fast {
block0(v0: i64):
    v1 = iconst.i64 0
    store v1, v0  ; v1 = 0
    v2 = iconst.i64 0
    store v2, v0+8  ; v2 = 0
    v3 = iconst.i64 0
    store v3, v0+16  ; v3 = 0
    return
}
native-x86_64-unknown-linux-gnu0\0\Vec\push[uint] function u0:0(i64, i64 uext) fast {
    sig0 = (i64) fast
    sig1 = (i64, i64 uext) -> i64 fast
    sig2 = (i64, i64 uext) fast
    fn0 = colocated u0:42 sig0
    fn1 = colocated u0:43 sig1
    fn2 = colocated u0:44 sig2

block0(v0: i64, v1: i64):
    v2 = load.i64 v0+8
    v3 = load.i64 v0+16
    v4 = icmp eq v2, v3
    brnz v4, block1
    jump block2

block2:
    jump block3

block1:
    call fn0(v0)
    jump block3

block3:
    v5 = load.i64 v0+8
    v6 = call fn1(v0, v5)
    call fn2(v6, v1)
    v7 = iconst.i64 1
    v8 = load.i64 v0+8
    v9 = iadd v8, v7  ; v7 = 1
    store v9, v0+8
    return
}
native-x86_64-unknown-linux-gnu3\write[uint] function u0:0(i64, i64 uext) fast {
block0(v0: i64, v1: i64):
    store v1, v0
    return
}
native-x86_64-unknown-linux-gnu0\0\Vec\get_mut_ptr[uint] function u0:0(i64, i64 uext) -> i64 fast {
block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 8
    v4 = imul v1, v3  ; v3 = 8
    v5 = iadd v2, v4
    return v5
}
native-x86_64-unknown-linux-gnu0\0\Vec\grow[uint] function u0:0(i64) fast {
    sig0 = (i64, i64 uext) -> i64 fast
    fn0 = u0:40 sig0

block0(v0: i64):
    v1 = iconst.i64 0
    v2 = load.i64 v0+16
    v3 = icmp eq v2, v1  ; v1 = 0
    brnz v3, block1
    jump block2

block2:
    v4 = iconst.i64 2
    v5 = load.i64 v0+16
    v6 = imul v5, v4  ; v4 = 2
    jump block3(v6)

block1:
    v7 = iconst.i64 8
    jump block3(v7)  ; v7 = 8

block3(v8: i64):
    store v8, v0+16
    v9 = load.i64 v0
    v10 = iconst.i64 8
    v11 = load.i64 v0+16
    v12 = imul v11, v10  ; v10 = 8
    v13 = call fn0(v9, v12)
    store v13, v0
    return
}
native-x86_64-unknown-linux-gnu0\0\Vec\new[uint] function u0:0(i64 sret) fast {
block0(v0: i64):
    v1 = iconst.i64 0
    store v1, v0  ; v1 = 0
    v2 = iconst.i64 0
    store v2, v0+8  ; v2 = 0
    v3 = iconst.i64 0
    store v3, v0+16  ; v3 = 0
    return
}
native-x86_64-unknown-linux-gnu0\Vec\drop[0\Vec[uint]] function u0:0(i64) fast {
    ss0 = explicit_slot 24
    sig0 = (i64, i64 uext) -> i64 fast
    sig1 = (i64 sret, i64) fast
    sig2 = (i64) fast
    sig3 = (i64) fast
    fn0 = colocated u0:25 sig0
    fn1 = colocated u0:49 sig1
    fn2 = colocated u0:48 sig2
    fn3 = u0:50 sig3

block0(v0: i64):
    v1 = iconst.i64 0
    jump block1(v1)  ; v1 = 0

block1(v2: i64):
    v5 -> v2
    v3 = load.i64 v0+8
    v4 = icmp eq v2, v3
    brnz v4, block2
    jump block3

block3:
    v6 = call fn0(v0, v5)
    v7 = stack_addr.i64 ss0
    call fn1(v7, v6)
    v8 = stack_addr.i64 ss0
    call fn2(v8)
    v9 = iconst.i64 1
    v10 = iadd.i64 v5, v9  ; v9 = 1
    v11 -> v10
    jump block4

block4:
    jump block1(v11)

block2:
    jump block5

block5:
    v12 = load.i64 v0
    call fn3(v12)
    return
}
native-x86_64-unknown-linux-gnu3\read[0\Vec[uint]] function u0:0(i64 sret, i64) fast {
block0(v0: i64, v1: i64):
    v2 = load.i64 aligned v1
    v3 = load.i64 aligned v1+8
    v4 = load.i64 aligned v1+16
    store aligned v2, v0
    store aligned v3, v0+8
    store aligned v4, v0+16
    return
}
native-x86_64-unknown-linux-gnu0\Vec\drop[uint] function u0:0(i64) fast {
    ss0 = explicit_slot 8
    sig0 = (i64, i64 uext) -> i64 fast
    sig1 = (i64) -> i64 uext fast
    sig2 = (i64) fast
    fn0 = colocated u0:26 sig0
    fn1 = colocated u0:51 sig1
    fn2 = u0:50 sig2

block0(v0: i64):
    v1 = iconst.i64 0
    jump block1(v1)  ; v1 = 0

block1(v2: i64):
    v5 -> v2
    v3 = load.i64 v0+8
    v4 = icmp eq v2, v3
    brnz v4, block2
    jump block3

block3:
    v6 = call fn0(v0, v5)
    v7 = call fn1(v6)
    stack_store v7, ss0
    v8 = stack_addr.i64 ss0
    v9 = iconst.i64 1
    v10 = iadd.i64 v5, v9  ; v9 = 1
    v11 -> v10
    jump block4

block4:
    jump block1(v11)

block2:
    jump block5

block5:
    v12 = load.i64 v0
    call fn2(v12)
    return
}
native-x86_64-unknown-linux-gnu3\read[uint] function u0:0(i64) -> i64 uext fast {
block0(v0: i64):
    v1 = load.i64 v0
    return v1
}


info: status: exit status: 0
 = info: stdout: 
 = info: stderr: 

